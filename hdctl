#!/usr/bin/env bash
#
###############################################################################
#                                                                             #
#                                    hdctl                                    #
#                                                                             #
#   Manage maintenance / devops tasks around hetida designer installations    #
#                                                                             #
#                                                                             #
###############################################################################
#
# LICENSE
#   Copyright © 2023 neusta analytics & insights GmbH
#
#   MIT License
#   see https://github.com/hetida/hetida-designer/blob/release/LICENSE
#
# INTRODUCTION
#   hdctl is a bash command line tool for managing typical maintenance /
#   devops tasks around hetida designer installations.
#
#   hdctl can export/import components and workflows from/to the backend api
#   while taking care of authentication. A typical use case is syncing
#   components / workflows from dev instances to test or prod instances.
#
#   Another use case is running maintenance operations, e.g. as described in
#   https://github.com/hetida/hetida-designer/blob/release/docs/cleanup.md
#   from the command line only, i.e. without needing docker.
#
#   hdctl is based on bash/coreutils + curl with the additional requirement
#   of awk and jq for some tasks that involve json wrangling. This enables
#   managing hetida designer instances from locations where no docker or
#   python installation is available or installing arbitrary dependencies
#   and software is difficult due to administrative / security restrictions.
#
# INSTALLATION
#   Just copy this bash script to the environment where you want to run it
#   from. There you need
#     * modern/recent bash (version >4)
#     * GNU coreutils
#     * curl (ideally >= 7.87.0)
#     * optionally awk and jq (https://stedolan.github.io/jq/) for some
#       subcommands that involve json unpacking
#
#   Notes:
#     * hdctl should run under Git Bash on Windows. Recent versions of Git
#       for Windows include curl >= 7.87.0 and gawk. jq must be installed
#       separately. If you experience problems please open an issue.
#     * Using nix, you can start an environment with all dependencies by
#       running
#         nix-shell \
#           -I nixpkgs=https://github.com/NixOS/nixpkgs/archive/nixos-unstable.tar.gz \
#           -p bashInteractive jq gawk coreutils curl
#       At least with the following fixed nixpkgs commit it should
#       definitely work:
#         nix-shell \
#           -I nixpkgs=https://github.com/NixOS/nixpkgs/archive/28319deb5ab05458d9cd5c7d99e1a24ec2e8fc4b.tar.gz \
#           -p bashInteractive jq gawk coreutils curl
#
#
# USAGE
#   Run
#       hdctl usage
#   to see detailed usage instructions and descriptions of all subcommands
#   and arguments.

set -e

######################## Initialize mutable Global variables ##################
ACCESS_TOKEN=""
EXPIRATION_EPOCH=0
_JQ_AVAILABLE=true

###############################################################################
#                                                                             #
#                              Logging functions                              #
#                                                                             #
###############################################################################

_info() {
    if [[ $SILENT = false ]]; then
        echo "${@}" >&2
    fi
}

_debug() {
    if [[ $VERBOSITY == "debug" ]]; then
        echo "${@}" >&2
    fi
}

_log_error() {
    echo "${@}" >&2
}

###############################################################################
#                                                                             #
#               System environment detection helper functions                 #
#                                                                             #
###############################################################################

_detect_jq() {
    if ! command -v jq 1>/dev/null; then
        _info "WARNING: jq not available. Some parameters/options cannot be used."
        _JQ_AVAILABLE=false
    else
        _info "Successfully detected jq in PATH."
    fi
}

_ensure_jq() {
    if ! command -v jq 1>/dev/null; then
        _log_error "Called command needs jq command line tool, which was not found. Aborting."
        exit 127
    fi
}

###############################################################################
#                                                                             #
#                                Usage / help                                 #
#                                                                             #
###############################################################################

usage() {
    if [ -n "${1-}" ]; then
        _log_error "--> ERROR: $1"
    fi

    echo "BASIC USAGE: Run"
    echo "  $0 SUBCOMMAND <parameters>"
    echo
    echo "EXAMPLES"
    echo
    echo "  FETCHING:"
    echo "    Write json list of all components from Physics category to stdout"
    echo
    echo "        $0 "'fetch --url-append "?category=Physics&type=COMPONENT"'
    echo
    echo "    Notes: * In these examples configuration like backend api url, auth etc is assumed to"
    echo "             come from ./hdctl.env file or HDCTL_* environment variables."
    echo "           * available query parameters of the backend api are documented in the openapi"
    echo "             documentation of the /api/transformations GET / PUT endpoints and the"
    echo "             /api/maintenance/* endpoints"
    echo "           * --url-append does not urlencode automatically."
    echo
    echo "    With recent curl (>= 7.87.0, from 2023 or later) you can also propagate query params"
    echo "    via --url-query which automatically url encodes them as follows (note the space char"
    echo "    in category):"
    echo
    echo "        $0 "'fetch -- --url-query "category=Anomaly Detection" --url-query "type=COMPONENT"'
    echo
    echo "    Export json list of transformation revisions of category Physics into single file,"
    echo "    pretty printing the json by piping it through jq:"
    echo
    echo "        $0 fetch -- -d "'"category=Physics"'" | jq > physics_trafos.json"
    echo
    echo "    Export all non-deprecated workflows into directory structure at ./exported_trafos including"
    echo "    their dependencies. The directory and subdirectories for type and catgeory will be created"
    echo "    if necessary (This command needs awk and jq!)"
    echo
    echo "        $0 "'fetch --export-directory ./exported_trafos -- \'
    echo '          --url-query "type=WORKFLOW"\'
    echo '          --url-query "include_dependencies=true"\'
    echo '          --url-query "include_deprecated=false"'
    echo
    echo "  PUSHING:"
    echo '    Import from export directory only the workflows with name "Combine two Series'
    echo '    into DataFrame" which are released (there may be drafts or deprecated revisions)'
    echo "    together with their dependencies. Overwrite released trafo revs if necessary:"
    echo
    echo "      $0 "'push --export-trafos ./exported_trafos --\'
    echo '        --url-query "name=Combine two Series into DataFrame"\'
    echo '        --url-query "include_dependencies=true"\'
    echo '        --url-query "allow_overwrite_released=true"\'
    echo '        --url-query "state=RELEASED"'
    echo
    echo "    The response shows which trafo revs actually where imported and which where ignored."
    echo "    You may want to pipe it through jq for pretty printing."
    echo
    echo "    Import released components from json file containing list of trafo revs allowing overwriting"
    echo "    of released components:"
    echo
    echo "      $0 "'push physics_trafos.json --url-append "?type=COMPONENT&state=RELEASED&allow_overwrite_released=true"'
    echo
    echo "  MAINTENANCE:"
    echo "    Examples here assume that the maintenance secret is set either in hdctl.env file"
    echo "    (MAINTENANCE_SECRET) or as environment variable HDCTL_MAINTENANCE_SECRET."
    echo
    echo "    Deprecate all but the latest released (i.e. by release date, disregarding version tag!)"
    echo "    revision of every transformation revision group:"
    echo
    echo "      $0 deprecate_all_but_latest_per_group"
    echo
    echo "    Purge your installation: Delete everything and afterwards redeploy base trafos from"
    echo "    running backend (WARNING: irreversible data loss!):"
    echo
    echo "      $0 purge"
    echo
    echo "GENERAL HINTS"
    echo "Parameters can be supplied with increasing priority as follows:"
    echo " * On startup a .env file is sourced if available, by default ./hdctl.env."
    echo "   You can configure its path via HDCTL_ENV_FILE environment variable. It should"
    echo "   define variables corresponding to settings of form NAME_IN_UPPER_CASE"
    echo " * Environment variables prefixed with HDCTL_ (HDCTL_NAME_IN_UPPER_CASE) are interpreted"
    echo "   and may override NAME_IN_UPPER_CASE from the env file."
    echo " * explicit command line parameters override all these settings"
    echo
    echo "On the command line values to  parameters are separated with space inbetween like"
    echo "    --backend-api-url http://localhost:8080/api"
    echo "or"
    echo "    -b http://localhost:8080/api"
    echo "(i.e. not --backend-api-url=http://localhost:8080/api )"
    echo
    echo "Most parameters are general and can be set independantly of subcommands. Whether they"
    echo "are used depends on the actual subcommand invoked."
    echo
    echo "Arguments after -- are gathered. If the subcommand invokes curl, they are appended to "
    echo "the curl command at the end. This allows for example to usq the --url-query curl argument"
    echo "to control filters when fetching / pushing, as you can see in the examples above."
    echo
    echo "In the following we reference settings by naming them by the variable as it"
    echo "would occur in the .env file (i.e. NAME_IN_UPPER_CASE). Recall that the corresponding"
    echo "environment variable then is HDCTL_NAME_IN_UPPER_CASE."
    echo
    echo "Subcommands typically make http requests to a hd backend api configured via"
    echo "HD_BACKEND_API_URL pointing to the /api resource of the backend service, e.g."
    echo "  http://localhost:8080/api"
    echo
    echo "Authentication is handled as follows:"
    echo "  * if DIRECT_ACCESS_TOKEN is set, it is passed as Bearer token."
    echo "  * if DIRECT_ACCESS_TOKEN is not set / empty string:"
    echo "    * if AUTH_URL is set (e.g. http://localhost/auth)"
    echo "      * if USERNAME is set / non-zero, an access token is tried to be obtained"
    echo "        with PASSWORD from the auth provider at AUTH_URL via openidconnect standard"
    echo "        using password grant credential flow."
    echo "      * if USERNAME is not set, CLIENT_ID and CLIENT_SECRET are used to obtain"
    echo "        an access token from the auth provider at AUTH_URL via openidconnect standard"
    echo "        using client credential grant flow."
    echo "    * if AUTH_URL is not set / empty string the backend is expected to be reachable"
    echo "      without authentication."
    echo
    echo "PARAMETERS"
    echo "  Mandatory arguments to long options are mandatory for short options too. Name of"
    echo "  corresponding environment variable with HDCTL_ prefix in parantheses."
    echo
    echo "  -e | --env-file PATH                     (HDCTL_ENV_FILE)"
    echo "      path to env file that will be sourced at startup. Defaults to ./hdctl.env."
    echo "      If set to non-default value it must exist."
    echo
    echo "  -b | --backend-api-url URL              (HDCTL_HD_BACKEND_API_URL)"
    echo "      URL of the backend api resource, e.g. http://localhost:8080/api"
    echo
    echo "  --insecure-backend                      (HDCTL_VERIFY_BACKEND_API_URL)"
    echo "      do not verify https when communicating with the backend."
    echo
    echo "  -d | --export-directory PATH            (HDCTL_EXPORT_DIRECTORY)"
    echo "      PATH to a directory where data should be exported to (fetch) or loaded from (push)."
    echo "      fetch will create the directory and distribute downloaded trafo revs into json files"
    echo "      at pathes like, using jq and awk"
    echo "          PATH/{workflows,components}/<CATEGORY>/<NAME>_<VERSION_TAG>_<ID>.json"
    echo "      If this is not set, fetch will instead output a json list of all downloaded trafo revs"
    echo "      to stdout."
    echo "      push will use the directory as source if this is set. If not, push expects a path"
    echo "      to a single json file containing an array of trafo revs as first argument instead."
    echo
    echo "  -a | --auth-url AUTH_URL                (HDCTL_AUTH_URL)"
    echo "      Openidconnect auth provider auth endpoint, e.g. https://localhost/auth"
    echo
    echo "  --insecure-auth                         (HDCTL_VERIFY_AUTH_URL)"
    echo "      do not verify https when communicating with auth provider"
    echo
    echo "  -t | --access-token TOKEN               (HDCTL_DIRECT_ACCESS_TOKEN)"
    echo "      If this is provided, it will be used as Bearer access token and no communication"
    echo "      with auth provider will happen. Make sure that TOKEN is not expired."
    echo
    echo "  -r | --realm REALM                      (HDCTL_REALM)"
    echo "      openidconnect realm name that should be used."
    echo
    echo "  -c | --client-id CLIENT_ID              (HDCTL_CLIENT_ID)"
    echo "      The client id. Necessary for both password grant and client credential grant auth flow."
    echo
    echo "  -s | --client-secret CLIENT_SECRET     (HDCTL_CLIENT_SECRET)"
    echo "      The client secret when using client credential secret auth flow"
    echo
    echo "  -m | --maintenance-secret SECRET       (HDCTL_MAINTENANCE_SECRET)"
    echo "      Maintenance actions require a maintenance secret to be configured in the backend"
    echo "      and provided whith each maintenance endpoint request."
    echo
    echo "   -p | --url-append PARAMSTRING         (HDCTL_QUERY_URL_APPEND)"
    echo "       PARAMSTRING will be appended as-is to the url in curl invocations. Can be used"
    echo '       to provide query parameters, for example --url-append "?type=COMPONENT&state=RELEASED"'
    echo
    echo "   -q | --quiet                          (HDCTL_SILENT)"
    echo "       suppress some output"
    echo
    echo "   -v | --verbose                        (HDCTL_VERBOSITY)"
    echo '       The default is "info". Setting it will switch to "debug" and send some additional debug'
    echo "       output to stderr"
    echo
    echo "    --"
    echo "       All command line arguments following -- will be gathered and for curl-invoking"
    echo "       subcommands they will be appended to the curl call."
    echo
    echo "AVAILABLE CUBCOMMANDS BY TOPIC"
    echo "  FETCH / EXPORT / DOWNLOAD"
    echo "    The fetch subcommand downloads / exports transformation revisions from the hetida"
    echo "    designer backends using curl, handling auth if necessary. If an export directory"
    echo "    is set it will use jq and awk to distribute the transformation revisions as single"
    echo "    json file each into a directory structure, separating by type and category"
    echo
    echo "      $0 fetch -d EXPORT_DIRECTORY"
    echo
    echo "    Otherwise it will output a json array to stdout"
    echo
    echo "      $0 fetch"
    echo
    echo "    Piping its output to a file creates a single json file containing all fetched"
    echo "    transformation revisions. See -d parameter for details."
    echo
    echo "    By supplying url query parameters as described in the examples at the beginning, only"
    echo "    a part of all available trafo revs can be fetched. See the openapi documentation"
    echo "    of the backend /api/transformations GET endpoint for available parameters."
    echo
    echo "  PUSH / IMPORT / UPLOAD"
    echo "    The push subcommand uploads / imports transformation revisions (in)to the hetida"
    echo "    designer backend using curl, handling auth if necessary. If an export directory"
    echo "    is set it will gather the json files there for the upload:"
    echo
    echo "      $0 push -d -d EXPORT_DIRECTORY"
    echo
    echo "    Otherwise it expects a path to a json file containing a json array of transformation"
    echo "    revisions as first argument:"
    echo
    echo "      $0 push ./exported_trafos.json"
    echo
    echo "    Similarly to the fetch subcommand, by supplying url query parameters, only"
    echo "    a part of all provided trafo revs will be imported. See the openapi documentation"
    echo "    of the backend /api/transformations PUT endpoint for available parameters."
    echo
    echo "  MAINTENANCE"
    echo "    These subcommands correspond to the hd backend api maintenance endpoints."
    echo "    All maintenance subcommands require a non-zero length alphanumeric maintenance"
    echo "    secret to be set at both server and client side:"
    echo "      * server side: configuration of hd backend service (HD_MAINTENANCE_SECRET)"
    echo "      * client side: via -m / --maintenance-secret CLI parameters or environment"
    echo "        variable (HDCTL_MAINTENANCE_SECRET or MAINTENANCE_SECRET in env file)"
    echo
    echo "    See https://github.com/hetida/hetida-designer/blob/release/docs/cleanup.md"
    echo "    or the OpenAPI docs of a started hd backend service for details on what"
    echo "    they do exactly."
    echo
    echo "    Again, query parameters can be provided as described above for fetch and push."
    echo
    echo "    Maintenance subcommands:"
    echo
    echo "      $0 deprecate_all_but_latest_per_group"
    echo
    echo ""
    echo "      $0 delete_drafts"
    echo "      $0 delete_unused_deprecated"
    echo "      $0 purge"
    echo "      $0 deploy_base_trafos"
    echo "      $0 autoimport"
    echo
}

help() {
    usage
}

###############################################################################
#                                                                             #
#                           General helper functions                          #
#                                                                             #
###############################################################################

reverse_string() {
    # pipe a string into this function to reverse it!
    var="$(cat)" # read from stdin
    len="${#var}"
    i=0
    rev=""
    while ((i < len)); do rev="${var:i++:1}$rev"; done
    echo "$rev"
}

###############################################################################
#                                                                             #
#                               Token management                              #
#                                                                             #
###############################################################################

get_token_response() {
    curl_args=()
    if [[ $VERIFY_AUTH_URL = false ]]; then
        curl_args+=("--insecure")
    fi

    curl_args+=("-d" "client_id=$CLIENT_ID")

    if [[ -n "$USERNAME" ]]; then
        _debug "Using password credential grant mode."
        curl_args+=("-d" 'grant_type=password' "-d" "username=$USERNAME" "-d" "password=$PASSWORD")
    else
        _debug "Using client credential grant mode"
        curl_args+=("-d" 'grant_type=client_credentials' "-d" "client_secret=$CLIENT_SECRET")
    fi

    curl -s "${curl_args[@]}" "$AUTH_URL/realms/$REALM/protocol/openid-connect/token"
}

extract_access_token() {
    no_space_and_newline="$(echo "$1" | tr -d ' ' | tr -d '\n')"
    _debug "$no_space_and_newline"
    removed_prefix="${no_space_and_newline#*\"access_token\":\"}"
    ACCESS_TOKEN="$(echo "$removed_prefix" | cut -d '"' -f 1)"
}

extract_expiration() {
    no_space_and_newline="$(echo "$1" | tr -d ' ' | tr -d '\n')"
    _debug "$no_space_and_newline"
    removed_prefix="${no_space_and_newline#*\"expires_in\":}"
    echo "$removed_prefix" | cut -d ',' -f 1 | cut -d '}' -f 1
}

set_expiration_epoch() {
    local token_resp
    token_resp="$1"
    local expires_in
    expires_in="$(extract_expiration "$token_resp")"
    issue_epoch=$(date +%s)
    EXPIRATION_EPOCH=$(($issue_epoch + $expires_in - 10)) # 10 seconds buffer
}

get_access_token() {
    local token_resp
    token_resp="$(get_token_response)"
    set_expiration_epoch "$token_resp"
    extract_access_token "$token_resp"
}

check_expiration() {
    if (($(date +%s) > $EXPIRATION_EPOCH)); then
        return 1
    fi
    return 0
}

ensure_access_token() {
    if [[ -n "$DIRECT_ACCESS_TOKEN" ]]; then
        _debug "Using directly provided access token. Expiration unknown!"
        ACCESS_TOKEN="$DIRECT_ACCESS_TOKEN"
        return
    elif [[ -z "$AUTH_URL" ]]; then
        _debug "No auth configured (empty auth url). Not setting token."
        return
    elif [[ -z "$ACCESS_TOKEN" ]] || ! check_expiration; then
        _info "Need to get/renew access token."
        get_access_token
    else
        _debug "Access still token okay."
    fi
}

###############################################################################
#                                                                             #
#                                Maintenance                                  #
#                                                                             #
###############################################################################

##################### ~=~ maintenance helper functions ~=~ ####################

_ensure_maintenance_secret() {
    if [[ -z "$MAINTENANCE_SECRET" ]]; then
        _log_error "Setting maintenance secret required for requested subcommand! Aborting."
        exit 1
    fi
}

######################### ~=~ maintenance actions ~=~ #########################

# Deprecate old transformation revision and keep only latest

#     A transformation revision is considered "old" if it is released and there is a newer
#     released transformation revision (i.e. newer release timestamp) in the same group.

#     Note that this has nothing to to with version tags or any versioning scheme!
deprecate_all_but_latest_per_group() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/deprecate_all_but_latest_per_group$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

# Delete all transformation revisions with state DRAFT
delete_drafts() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/delete_drafts$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

# Delete all unused deprecated transformation revisions

#     "Unused" deprecated transformation revisions are those that are either not used in any workflow
#     or only in workflows that themselves are deprecated (and hence will be deleted as well).

#     This handles nesting, i.e. a deprecated trafo rev will not be deleted if it is used indirectly
#     across multiple nesting levels in a workflow which is not deprecated.
delete_unused_deprecated() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/delete_unused_deprecated$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

# Purge and reinstall base components/workflows

#     This deletes all transformation revisions and afterwards deploys the base
#     components and workflows present in the running backend instance's image at the
#     default path.
purge() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/purge$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

# Trigger deployment of base transformations from the running backend
# interesting query parameters are
# * allow_overwrite_released
# * update_component_code
deploy_base_trafos() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/deploy_base_trafos$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

# Trigger autoimport
#
# note that each import is configured by accompagniying config json file, so
# this has no query params
autoimport() {
    _setup "${@}"
    _ensure_maintenance_secret
    ensure_access_token

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X POST \
        -H "Authorization: Bearer $ACCESS_TOKEN" \
        -H "Content-Type: application/json" \
        -d '{"maintenance_secret":"'"$MAINTENANCE_SECRET"'"}' \
        "$HD_BACKEND_API_URL/maintenance/autoimport$QUERY_URL_APPEND" \
        "${REMAINING_ARGS[@]}"
}

###############################################################################
#                                                                             #
#                              Import into hd                                 #
#                                                                             #
###############################################################################

_import_multi_trafo_json_file() {
    _file_path="$1"
    shift

    ensure_access_token

    # put to /transformations endpoint
    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi
    curl "${curl_args[@]}" -X PUT -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" -d @"$_file_path" "$HD_BACKEND_API_URL/transformations$QUERY_URL_APPEND" "${@}"
}

_import_from_dir() {
    # load all trafos into one big json
    _all_trafos_json='[  ' # 2 extra spaces, see comma + newline removal below
    for f in $(find "$EXPORT_DIRECTORY" -name '*.json'); do
        _all_trafos_json+="$(cat "$f")"
        _all_trafos_json+=","$'\n' # add comma and newline
    done
    _all_trafos_json="${_all_trafos_json::-2}" # remove last comma and newline
    _all_trafos_json+=']'

    ensure_access_token

    local _temp_file
    _temp_file="$(mktemp)"
    echo "$_all_trafos_json" >"$_temp_file"

    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi

    curl "${curl_args[@]}" -X PUT -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" -d @"$_temp_file" "$HD_BACKEND_API_URL/transformations$QUERY_URL_APPEND" "${@}"

    rm "$_temp_file"
}

push() {
    _setup "${@}"
    if [[ -z "$EXPORT_DIRECTORY" ]]; then
        _import_multi_trafo_json_file "${REMAINING_ARGS[@]}"
    else
        _import_from_dir "${REMAINING_ARGS[@]}"
    fi
}

###############################################################################
#                                                                             #
#                              Export from hd                                 #
#                                                                             #
###############################################################################

# Write a json array of all trafos to stdout
_export_to_json() {
    ensure_access_token
    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi

    curl "${curl_args[@]}" -X GET -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" "$HD_BACKEND_API_URL/transformations$QUERY_URL_APPEND" -G "${REMAINING_ARGS[@]}"
}

### Export into dir
_slugify() {
    awk '{
              gsub(/[äÄ]/,"a");
              gsub(/[öÖ]/,"o");
              gsub(/[üÜ]/,"u");
              gsub(/[^0-9a-zA-Z -]/,""); 
              gsub(/^[ \t\r\n]+/, ""); 
              gsub(/[ \t\r\n]+$/, ""); 
              gsub(/[ ]+/,"_");
              print tolower($0);
        }'
}

_slugify_arg() {
    printf "%s" "$1" | _slugify
}

_subpath() {
    _id="$1"
    _name="$2"
    _category="$3"
    _type="$4"
    _version_tag="$5"

    printf "%s" "${_type,,}"s/"$(_slugify_arg "$_category")"/"$(_slugify_arg "$_name")"_"$(_slugify_arg "$_version_tag")"_"$_id".json
}

_export_to_dir() {
    _ensure_jq
    ensure_access_token
    curl_args=()
    if [[ $VERIFY_BACKEND_API_URL = false ]]; then
        curl_args+=("--insecure")
    fi

    mkdir -p "$EXPORT_DIRECTORY"

    # echo curl "${curl_args[@]}" -X GET -G -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" "$HD_BACKEND_API_URL/transformations$QUERY_URL_APPEND" "${REMAINING_ARGS[@]}"
    # write each trafo revision to its respective directory

    for row in $(curl "${curl_args[@]}" -X GET -G -H "Authorization: Bearer $ACCESS_TOKEN" -H "Content-Type: application/json" "$HD_BACKEND_API_URL/transformations$QUERY_URL_APPEND" "${REMAINING_ARGS[@]}" | jq -r '.[] | @base64'); do
        decoded_row="$(echo ${row} | base64 --decode)"

        _id="$(echo "$decoded_row" | jq -r '.id')"
        _name="$(echo "$decoded_row" | jq -r '.name')"
        _category="$(echo "$decoded_row" | jq -r '.category')"
        _type="$(echo "$decoded_row" | jq -r '.type')"
        _version_tag="$(echo "$decoded_row" | jq -r '.version_tag')"

        _file_path="$EXPORT_DIRECTORY"/"$(_subpath "$_id" "$_name" "$_category" "$_type" "$_version_tag")"

        _debug "Writing file to $_file_path"
        mkdir -p "$(dirname "$_file_path")"
        echo "${row}" | base64 --decode | jq >"$_file_path"
    done

}

fetch() {
    _setup "${@}"
    if [[ -z "$EXPORT_DIRECTORY" ]]; then
        _export_to_json
    else
        _export_to_dir
    fi
}

###############################################################################
#                                                                             #
#                                Sync commands                                #
#                                                                             #
###############################################################################

sync() {
    local sync_command="$1"

    if [[ "$sync_command" != "push" ]] && [[ "$sync_command" != "pull" ]]; then
        _log_error "Only allowed sync actions are pull and push. Got $sync_command instead. Aborting"
        exit 1
    fi

    local sync_instance="$2"

    if [[ -z "$sync_instance" ]]; then
        _log_error "no hd instance specified. Aborting."
        exit 1
    fi

    shift
    shift

    local instance_file="${sync_instance}.hd-instance"
    local instance_creds_file="${sync_instance}.hd-creds"

    source "$instance_file"
    source "$instance_creds_file"

    _initialize_variables

    local additional_arguments=()
    if [[ "$sync_command" == "pull" ]]; then
        if [[ -n "$PULL_QUERY_URL_APPEND" ]]; then
            QUERY_URL_APPEND="$PULL_QUERY_URL_APPEND"
        fi
        if [[ -n "$PULL_ADDITIONAL_ARGUMENTS" ]]; then
            additional_arguments=("${PULL_ADDITIONAL_ARGUMENTS[@]}")
        fi
    fi

    if [[ "$sync_command" == "push" ]]; then
        if [[ -n "$PUSH_QUERY_URL_APPEND" ]]; then
            QUERY_URL_APPEND="$PUSH_QUERY_URL_APPEND"
        fi
        if [[ -n "$PUSH_ADDITIONAL_ARGUMENTS" ]]; then
            additional_arguments=("${PUSH_ADDITIONAL_ARGUMENTS[@]}")
        fi
    fi

    _parse_global_options "${additional_arguments[@]}" "${@}"
    _validate_global_parameters

    # Additionally required validations for syncing

    if [[ -z "$EXPORT_DIRECTORY" ]]; then
        _log_error "No export directory specified. Aborting."
        exit 1
    fi

    # Now we are ready to actually run the requested sync command

    if [[ "$sync_command" == "pull" ]]; then
        # clear up directory first
        rm -Rf "$EXPORT_DIRECTORY"

        _export_to_dir
    elif [[ "$sync_command" == "push" ]]; then
        _import_from_dir
    fi

}

###############################################################################
#                                                                             #
#             Setup/handle params, environment variables, env file            #
#                                                                             #
###############################################################################

REMAINING_ARGS=()

# must be called with all command line arguments
_obtain_env_file_config() {
    ENV_FILE_PATH="${HDCTL_ENV_FILE:-"./hdctl.env"}"

    while [[ "$#" -gt 0 ]]; do case $1 in
        -e | --env-file)
            ENV_FILE_PATH="$2"
            shift
            shift
            break
            ;;
        --)
            shift
            break
            ;;
        *)
            # ignore everything else
            shift
            ;;
        esac done
}

_source_env_file() {
    if [[ -z "$ENV_FILE_PATH" ]]; then
        _debug "Env file path explicitely unset!"
    elif [[ ! -e "$ENV_FILE_PATH" ]]; then
        if [[ "$ENV_FILE_PATH" == "./hdctl.env" ]]; then
            _debug "No env file at default path. Continue without sourcing"
        else
            _log_error "Explicit env file path set, but could not find file! Aborting."
            exit 1
        fi
    else
        _debug "Sourcing env file $ENV_FILE_PATH."
        # shellcheck disable=SC1090
        source "$ENV_FILE_PATH"
    fi
}

_initialize_variables() {
    # initialize with increasing priority
    # * from defaults
    # * from env file variables of form VARIABLE_NAME
    # * from prefixed environment variables, i.e. of form HDCTL_VARIABLE_NAME

    SILENT="${HDCTL_SILENT:-"${SILENT:-false}"}"
    VERBOSITY="${HDCTL_VERBOSITY:-"${VERBOSITY:-"info"}"}"

    ##### Content
    EXPORT_DIRECTORY="${HDCTL_EXPORT_DIRECTORY:-"${EXPORT_DIRECTORY:-""}"}"

    ##### HD backend

    HD_BACKEND_API_URL="${HDCTL_HD_BACKEND_API_URL:-"${HD_BACKEND_API_URL:-"http://localhost/api"}"}"
    VERIFY_BACKEND_API_URL="${HDCTL_VERIFY_BACKEND_API_URL:-"${VERIFY_BACKEND_API_URL:-true}"}"
    QUERY_URL_APPEND="${HDCTL_QUERY_URL_APPEND:-"${QUERY_URL_APPEND:-""}"}"

    ##### Authentication
    DIRECT_ACCESS_TOKEN="${HDCTL_DIRECT_ACCESS_TOKEN:-"${DIRECT_ACCES_TOKEN:-""}"}"
    AUTH_URL="${HDCTL_AUTH_URL:-"${AUTH_URL:-""}"}"
    USERNAME="${HDCTL_USERNAME:-"${USERNAME:-""}"}"
    PASSWORD="${HDCTL_PASSWORD:-"${PASSWORD:-""}"}"
    CLIENT_ID="${HDCTL_CLIENT_ID:-"${CLIENT_ID:-""}"}"
    CLIENT_SECRET="${HDCTL_CLIENT_SECRET:-"${CLIENT_SECRET:-""}"}"
    REALM="${HDCTL_REALM:-"${REALM:-"hetida"}"}"
    VERIFY_AUTH_URL="${HDCTL_VERIFY_AUTH_URL:-"${VERIFY_AUTH_URL:-true}"}"

    ##### Maintenance authorization
    MAINTENANCE_SECRET="${HDCTL_MAINTENANCE_SECRET:-"${MAINTENANCE_SECRET:-""}"}"
}

_parse_global_options() {

    REMAINING_ARGS=()
    while [[ "$#" -gt 0 ]]; do case $1 in
        -e | --env-file)
            ENV_FILE_PATH="$2"
            shift
            shift
            ;;
        -b | --backend-api-url)
            HD_BACKEND_API_URL="$2"
            shift
            shift
            ;;
        --insecure-backend)
            VERIFY_BACKEND_API_URL=false
            shift
            ;;
        -d | --export-directory)
            EXPORT_DIRECTORY="$2"
            shift
            shift
            ;;
        -a | --auth-url)
            AUTH_URL="$2"
            shift
            shift
            ;;
        --insecure-auth)
            VERIFY_AUTH_URL=false
            shift
            ;;
        -t | --access-token)
            DIRECT_ACCESS_TOKEN="$2"
            shift
            shift
            ;;
        -r | --realm)
            REALM="$2"
            shift
            shift
            ;;
        -c | --client-id)
            CLIENT_ID="$2"
            shift
            shift
            ;;
        -s | --client-secret)
            CLIENT_SECRET="$2"
            shift
            shift
            ;;
        -m | --maintenance-secret)
            MAINTENANCE_SECRET="$2"
            shift
            shift
            ;;
        -p | --url-append)
            QUERY_URL_APPEND="$2"
            shift
            shift
            ;;
        -q | --quiet)
            SILENT=true
            shift
            ;;
        -v | --verbose)
            VERBOSITY="debug"
            shift
            ;;
        --)
            shift
            break
            ;;
        *)
            REMAINING_ARGS+=("$1")
            shift
            ;;
            #Unknown parameter appended to REMAINING_ARGS for access by subcommands
        esac done
    REMAINING_ARGS=("${REMAINING_ARGS[@]}" "${@}") # concat with remaining arguments
}

# must be called with cli arguments
_params_setup() {
    _obtain_env_file_config "${@}"
    _source_env_file
    _initialize_variables
    _parse_global_options "${@}"
}

_validate_global_parameters() {
    # if [[ -n "$AUTH_URL" ]] && [[ -z "$CLIENT_SECRET" ]]; then
    #     _log_error "Auth Url set but no client secret provided. Please provide a client secret"
    #     _log_error 'via -s SECRET or an empty auth url via -a "" to deactivate client credential'
    #     _log_error "auth on the command line. Aborting."
    #     exit 1
    # fi

    if [[ -n "$MAINTENANCE_SECRET" ]]; then
        if [[ ! "$MAINTENANCE_SECRET" =~ ^[a-zA-Z0-9]+$ ]]; then
            _log_error "Only numbers and alphabet letters allowed for the maintenance secret."
            exit 1
        fi
    fi
}

# _setup must be called with args
# typical first function of any subcommand
_setup() {
    _params_setup "${@}"
    _validate_global_parameters
}

###############################################################################
#                                                                             #
#                             Subcommand Execution                            #
#                                                                             #
###############################################################################

_fn_exists() {
    # Checks whether there exists a variable of type function with the given name.
    LC_ALL=C type "${1:-}" 2>/dev/null | grep -q 'function'
}

COMMAND=${1:-usage}
shift || true
ARGUMENTS=("${@}")

if [[ "$COMMAND" == "--help" || "$COMMAND" == "-h" ]]; then
    help
fi

if _fn_exists "$COMMAND"; then
    "$COMMAND" "${ARGUMENTS[@]}"
else
    usage "No subcommand $COMMAND"
fi
