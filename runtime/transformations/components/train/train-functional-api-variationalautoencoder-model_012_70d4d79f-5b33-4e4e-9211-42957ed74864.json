{
  "category": "Train",
  "content": "import pandas as pd\nimport tensorflow as tf\n\n# ***** DO NOT EDIT LINES BELOW *****\n# These lines may be overwritten if component details or inputs/outputs change.\nCOMPONENT_INFO = {\n    \"inputs\": {\n        \"Sampling\": \"ANY\",\n    },\n    \"outputs\": {\n        \"trained_variational_auto_encoder\": \"ANY\",\n    },\n    \"name\": \"Train Functional API VariationalAutoEncoder Model\",\n    \"category\": \"Train\",\n    \"description\": \"Train Functional API VariationalAutoEncoder Model with keras MNIST sample\",\n    \"version_tag\": \"0.1.2\",\n    \"id\": \"70d4d79f-5b33-4e4e-9211-42957ed74864\",\n    \"revision_group_id\": \"e0b7b84d-93d5-41ab-a86a-d39cf0e7ffd2\",\n    \"state\": \"RELEASED\",\n    \"released_timestamp\": \"2023-03-23T09:18:55.062081+00:00\",\n}\n\n\ndef main(*, Sampling):\n    # entrypoint function for this component\n    # ***** DO NOT EDIT LINES ABOVE *****\n    original_dim = 784\n    intermediate_dim = 64\n    latent_dim = 32\n\n    # Define encoder model.\n    original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n    x = tf.keras.layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n    z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n    z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n    z = Sampling()((z_mean, z_log_var))\n    encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n\n    # Define decoder model.\n    latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n    x = tf.keras.layers.Dense(intermediate_dim, activation=\"relu\")(latent_inputs)\n    outputs = tf.keras.layers.Dense(original_dim, activation=\"sigmoid\")(x)\n    decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n\n    # Define VAE model.\n    outputs = decoder(z)\n    vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n\n    # Add KL divergence regularization loss.\n    kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n    vae.add_loss(kl_loss)\n\n    # Load training sample.\n    (x_train, _), _ = tf.keras.datasets.mnist.load_data()\n    x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n\n    # Train.\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n    vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n    vae.fit(x_train, x_train, epochs=3, batch_size=64)\n    return {\"trained_variational_auto_encoder\": vae}",
  "description": "Train Functional API VariationalAutoEncoder Model with keras MNIST sample",
  "documentation": "# New Component/Workflow\n## Description\n## Inputs\n## Outputs\n## Details\n## Examples\n",
  "id": "70d4d79f-5b33-4e4e-9211-42957ed74864",
  "io_interface": {
    "inputs": [
      {
        "data_type": "ANY",
        "id": "290092b5-0fc0-46c5-a8d0-df9a7058757c",
        "name": "Sampling"
      }
    ],
    "outputs": [
      {
        "data_type": "ANY",
        "id": "0b998bfa-2715-4c18-a6aa-aa973e862621",
        "name": "trained_variational_auto_encoder"
      }
    ]
  },
  "name": "Train Functional API VariationalAutoEncoder Model",
  "released_timestamp": "2023-03-23T09:18:55.062081+00:00",
  "revision_group_id": "e0b7b84d-93d5-41ab-a86a-d39cf0e7ffd2",
  "state": "RELEASED",
  "test_wiring": {
    "input_wirings": [],
    "output_wirings": []
  },
  "type": "COMPONENT",
  "version_tag": "0.1.2"
}